Attention-via-Attention Neural Machine Translation
===================

Attention-via-Attention NMT based on **Sequencing**.
Published on AAAI18.

Please prepare the data file and model file ([box](https://app.box.com/s/lfot51n6rxb5104jhmng1oemtb1e23sx)), then run `eval.sh` to test the trained model.

BLEU on newtest2014 should be `34.92`.
